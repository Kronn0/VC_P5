{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import math \n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde cámara, detección con yolov8 y modelo nano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 46.0ms\n",
      "Speed: 1.0ms preprocess, 46.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 40.0ms\n",
      "Speed: 1.0ms preprocess, 40.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 40.0ms\n",
      "Speed: 1.0ms preprocess, 40.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 45.0ms\n",
      "Speed: 1.0ms preprocess, 45.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 38.0ms\n",
      "Speed: 1.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 40.0ms\n",
      "Speed: 1.0ms preprocess, 40.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 40.0ms\n",
      "Speed: 1.0ms preprocess, 40.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 41.0ms\n",
      "Speed: 1.0ms preprocess, 41.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "# Carga del modelo\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Nombre de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "\n",
    "# Captura desde lawebcam\n",
    "vid = cv2.VideoCapture(0)\n",
    "  \n",
    "while(True):      \n",
    "    # fotograma a fotograma\n",
    "    ret, img = vid.read()\n",
    "  \n",
    "    # si hay imagen válida\n",
    "    if ret:  \n",
    "        # Perform inference on an image\n",
    "        results = model(img, stream=True)\n",
    "        \n",
    "        # Para cada detección\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                # Contenedor\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "                \n",
    "                # Confianza\n",
    "                confidence = math.ceil((box.conf[0]*100))/100\n",
    "                print(\"Confidence --->\",confidence)\n",
    "\n",
    "                # Clase\n",
    "                cls = int(box.cls[0])\n",
    "                print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "                # Convierte identificador numérico de clase a un color RGB\n",
    "                escala = int((cls / len(classNames)) * 255 * 3)\n",
    "                if escala >= 255*2:\n",
    "                    R = 255\n",
    "                    G = 255\n",
    "                    B = escala - 255*2\n",
    "                else:\n",
    "                    if escala >= 255:\n",
    "                        R = 255\n",
    "                        G = escala - 255\n",
    "                        B = 0\n",
    "                    else:\n",
    "                        R = escala\n",
    "                        G = 0\n",
    "                        B = 0\n",
    "\n",
    "                # Dibuja el contenedor y clase\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "                cv2.putText(img, classNames[cls] , [x1, y1], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "        # Muestra fotograma\n",
    "        cv2.imshow('Vid', img)\n",
    "    \n",
    "    # Detenemos pulsado ESC\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "  \n",
    "# Libera el objeto de captura\n",
    "vid.release()\n",
    "# Destruye ventanas\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> vehicle\n",
      "0: 640x640 1 license-plate, 3 vehicles, 51.0ms\n",
      "Speed: 3.0ms preprocess, 51.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "Confidence ---> 0.74\n",
      "Class name --> vehicle\n",
      "Confidence ---> 0.28\n",
      "Class name --> vehicle\n",
      "0: 640x640 2 license-plates, 4 vehicles, 52.0ms\n",
      "Speed: 2.0ms preprocess, 52.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> vehicle\n",
      "Confidence ---> 0.83\n",
      "Class name --> vehicle\n",
      "0: 640x640 2 license-plates, 2 vehicles, 50.0ms\n",
      "Speed: 2.0ms preprocess, 50.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> vehicle\n",
      "Confidence ---> 0.84\n",
      "Class name --> vehicle\n",
      "0: 640x640 2 license-plates, 3 vehicles, 47.0ms\n",
      "Speed: 2.0ms preprocess, 47.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "Confidence ---> 0.93\n",
      "Class name --> vehicle\n",
      "0: 640x640 1 license-plate, 4 vehicles, 51.0ms\n",
      "Speed: 2.0ms preprocess, 51.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> vehicle\n",
      "Confidence ---> 0.87\n",
      "Class name --> vehicle\n",
      "0: 640x640 2 license-plates, 2 vehicles, 49.0ms\n",
      "Speed: 2.0ms preprocess, 49.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> vehicle\n",
      "0: 640x640 1 license-plate, 1 vehicle, 50.0ms\n",
      "Speed: 2.0ms preprocess, 50.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "Confidence ---> 0.82\n",
      "Class name --> vehicle\n",
      "0: 640x640 1 license-plate, 3 vehicles, 49.1ms\n",
      "Speed: 2.0ms preprocess, 49.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> vehicle\n",
      "Confidence ---> 0.71\n",
      "Class name --> vehicle\n",
      "0: 640x640 2 license-plates, 3 vehicles, 52.0ms\n",
      "Speed: 3.0ms preprocess, 52.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> vehicle\n",
      "0: 640x640 1 license-plate, 2 vehicles, 47.0ms\n",
      "Speed: 2.0ms preprocess, 47.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "Confidence ---> 0.86\n",
      "Class name --> vehicle\n",
      "0: 640x640 1 license-plate, 1 vehicle, 49.0ms\n",
      "Speed: 2.0ms preprocess, 49.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "Confidence ---> 0.67\n",
      "Class name --> vehicle\n",
      "0: 640x640 1 license-plate, 1 vehicle, 52.0ms\n",
      "Speed: 2.0ms preprocess, 52.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "Confidence ---> 0.83\n",
      "Class name --> vehicle\n",
      "Confidence ---> 0.41\n",
      "Class name --> vehicle\n",
      "0: 640x640 2 license-plates, 1 vehicle, 50.0ms\n",
      "Speed: 2.0ms preprocess, 50.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> vehicle\n",
      "0: 640x640 1 license-plate, 2 vehicles, 49.0ms\n",
      "Speed: 2.0ms preprocess, 49.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> vehicle\n",
      "0: 640x640 1 license-plate, 2 vehicles, 53.0ms\n",
      "Speed: 2.0ms preprocess, 53.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "Confidence ---> 0.92\n",
      "Class name --> vehicle\n",
      "0: 640x640 1 license-plate, 5 vehicles, 50.0ms\n",
      "Speed: 2.0ms preprocess, 50.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "Confidence ---> 0.88\n",
      "Class name --> vehicle\n",
      "0: 640x640 1 license-plate, 1 vehicle, 48.0ms\n",
      "Speed: 2.0ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "Confidence ---> 0.62\n",
      "Class name --> vehicle\n",
      "0: 640x640 1 license-plate, 2 vehicles, 49.0ms\n",
      "Speed: 3.0ms preprocess, 49.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "Confidence ---> 0.83\n",
      "Class name --> vehicle\n",
      "0: 640x640 1 license-plate, 1 vehicle, 48.0ms\n",
      "Speed: 3.0ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "Confidence ---> 0.94\n",
      "Class name --> vehicle\n",
      "Confidence ---> 0.87\n",
      "Class name --> vehicle\n",
      "0: 640x640 2 license-plates, 3 vehicles, 50.0ms\n",
      "Speed: 3.0ms preprocess, 50.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "Confidence ---> 0.96\n",
      "Class name --> vehicle\n",
      "0: 640x640 1 license-plate, 1 vehicle, 48.0ms\n",
      "Speed: 2.0ms preprocess, 48.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "Confidence ---> 0.91\n",
      "Class name --> vehicle\n",
      "0: 640x640 1 license-plate, 3 vehicles, 49.0ms\n",
      "Speed: 3.0ms preprocess, 49.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "Confidence ---> 0.89\n",
      "Class name --> vehicle\n",
      "0: 640x640 1 license-plate, 4 vehicles, 50.0ms\n",
      "Speed: 2.0ms preprocess, 50.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "Confidence ---> 0.84\n",
      "Class name --> vehicle\n",
      "0: 640x640 1 license-plate, 3 vehicles, 53.0ms\n",
      "Speed: 2.0ms preprocess, 53.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2  \n",
    "import math \n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Carga del modelo\n",
    "#model = YOLO('yolov8n.pt')\n",
    "model = YOLO('datasets/350_images/runs/detect/train4/weights/best.pt')\n",
    "\n",
    "# Nombre de las distintas clases\n",
    "# classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "#               \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "#               \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "#               \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "#               \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "#               \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "#               \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "#               \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "#               \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "#               \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "#               ]\n",
    "\n",
    "classNames = [\"vehicle\", \"license-plate\"]\n",
    "\n",
    "#carpeta_fotos = \"C:\\\\Users\\\\miica\\\\Desktop\\\\Uni\\\\VC\\\\VC_Practica4\\\\otsedom.github.io\\\\VC\\\\P5\\\\Coches con matriculas\\\\Coches con matriculas\"\n",
    "carpeta_fotos = \"C:\\\\Users\\\\miica\\\\.conda\\\\envs\\\\VC_P1\\\\P5\\\\datasets\\\\350_images\\\\train\\\\images\"\n",
    "\n",
    "# Lista de fotos de la carpeta\n",
    "imagenes = os.listdir(carpeta_fotos)\n",
    "\n",
    "contador = 0\n",
    "# Itera sobre cada archivo en la carpeta\n",
    "for img in imagenes:    \n",
    "\n",
    "    # Verificamos si el archivo es una imagen\n",
    "    if img.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "        contador += 1\n",
    "        # Construye la ruta completa de la imagen\n",
    "        ruta_imagen = os.path.join(carpeta_fotos, img)\n",
    "\n",
    "        # Lee la imagen\n",
    "        imagen = cv2.imread(ruta_imagen)\n",
    "        # Obtenemos el alto y el ancho para comprobar que los puntos no se salgan de las dimensiones de la imagen\n",
    "        alto, ancho = imagen.shape[:2]\n",
    "\n",
    "        # Perform inference on an image\n",
    "        results = model(imagen, stream=True)\n",
    "\n",
    "        # Para cada detección\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "            \n",
    "            for box in boxes:\n",
    "\n",
    "                # Nombre de las clases detectadas, filtra por coche\n",
    "                boxClassName = classNames[int(box.cls[0])]\n",
    "                \n",
    "                if boxClassName == \"car\" or boxClassName == \"truck\" or boxClassName == \"vehicle\":\n",
    "\n",
    "                    # Contenedor\n",
    "                    x1, y1, x2, y2 = box.xyxy[0]\n",
    "                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "                    \n",
    "                    # Puntos intermedios para buscar\n",
    "                    centroX = int((x1 + x2)/2)\n",
    "                    centroY = int((y1 + y2)/2) - int((y1 + y2)/8)\n",
    "                    \n",
    "                    centroX = max(0, min(centroX, ancho - 1))\n",
    "                    centroY = max(0, min(centroY, alto - 1))\n",
    "\n",
    "                    # Region de interes para encontrar la matricula\n",
    "                    roi = imagen[centroY:y2, x1: x2]\n",
    "\n",
    "                    # Convertimos la zona de interes a gris\n",
    "                    imagen_gris = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    # Desenfoque Gaussiano para reducir ruido y permitirnos mejorar al deteccion de los bordes de la matricula\n",
    "                    imagen_gris = cv2.GaussianBlur(imagen_gris, (3,3), 0)\n",
    "                    \n",
    "                    # Aplicamos umbral                    \n",
    "                    blockSize = 15\n",
    "                    C = 2\n",
    "                    umbral = cv2.adaptiveThreshold(imagen_gris, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, blockSize=blockSize, C=C)                    \n",
    "\n",
    "                    # Buscamos los contornos en roi umbralizada\n",
    "                    contornos, _ = cv2.findContours(umbral, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                    contornos_validos = {}\n",
    "                    for contorno in contornos:\n",
    "                        \n",
    "                        # Calcula el perimetro del contorno\n",
    "                        perimetro = cv2.arcLength(contorno, True)\n",
    "\n",
    "                        # Devuelve los puntos que se aproximan al polígono que crea el contorno\n",
    "                        approx = cv2.approxPolyDP(contorno, 0.02 * perimetro, True)\n",
    "                        \n",
    "                        if len(approx) == 4:\n",
    "                            \n",
    "                            # Calcula el area\n",
    "                            area = cv2.contourArea(contorno)  \n",
    "\n",
    "                            # Margen de area pequeño para quitar los contornos diminutos                            \n",
    "                            if 500 < area:\n",
    "                                \n",
    "                                diff_x_lado1 = abs(approx[1][0][0] - approx[0][0][0])\n",
    "                                diff_x_lado2 = abs(approx[2][0][0] - approx[3][0][0])\n",
    "                                \n",
    "                                diff_y_lado1 = abs(approx[2][0][1] - approx[1][0][1])\n",
    "                                diff_y_lado2 = abs(approx[3][0][1] - approx[0][0][1])\n",
    "\n",
    "                                # Calculamos diferencia de areas para comprobar que sea un rectangulo\n",
    "                                #area1 = diff_x_lado1 * diff_y_lado1\n",
    "                                #area2 = diff_x_lado2 * diff_y_lado2\n",
    "                                #diff_area = abs(area1 - area2)\n",
    "                                umbral_diferencia_x = 40\n",
    "                                umbral_diferencia_y = 40\n",
    "                                \n",
    "                                if diff_x_lado1 < umbral_diferencia_x and diff_x_lado2 < umbral_diferencia_x:\n",
    "                                    xText = np.min(approx[:, :, 0])\n",
    "                                    yText = np.min(approx[:, :, 1])\n",
    "                                    contornos_validos[area] = approx\n",
    "                                    #cv2.drawContours(roi, [approx], 0, (0, 255, 0), 2)\n",
    "                                # Calcula la relación de aspecto que debería acercarse a un valor de 2.0                            \n",
    "                                # x, y, w, h = cv2.boundingRect(approx)\n",
    "                                # relacion_aspecto = w / float(h)\n",
    "                                # if 1.0 < relacion_aspecto < 5:\n",
    "                                #     relacion_area = area / relacion_aspecto\n",
    "\n",
    "                                #     if relacion_area < 15000:\n",
    "                                #         xText = np.min(approx[:, :, 0])\n",
    "                                #         yText = np.min(approx[:, :, 1])                                    \n",
    "                                #         cv2.drawContours(roi, [approx], 0, (0, 255, 0), 2)                                        \n",
    "                                #         cv2.putText(roi, \"matricula\" , (xText, yText), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                    if contornos_validos:\n",
    "                        mayor_area = max(contornos_validos.keys())\n",
    "                        contorno_mayor_area = contornos_validos[mayor_area]\n",
    "                        xText = np.min(contorno_mayor_area[:, :, 0])\n",
    "                        yText = np.min(contorno_mayor_area[:, :, 1])\n",
    "                        cv2.drawContours(roi, [contorno_mayor_area], 0, (0, 255, 0), 2)\n",
    "                        cv2.putText(roi, \"matricula\" , (xText, yText), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                    cv2.rectangle(imagen, (x1, centroY), (x2, y2), (255, 255, 255), 3)\n",
    "\n",
    "                    # Confianza\n",
    "                    confidence = math.ceil((box.conf[0]*100))/100\n",
    "                    print(\"Confidence --->\",confidence)\n",
    "\n",
    "                    # Clase\n",
    "                    cls = int(box.cls[0])\n",
    "                    print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "                    # Convierte identificador numérico de clase a un color RGB\n",
    "                    escala = int((cls / len(classNames)) * 255 * 3)\n",
    "                    if escala >= 255*2:\n",
    "                        R = 255\n",
    "                        G = 255\n",
    "                        B = escala - 255*2\n",
    "                    else:\n",
    "                        if escala >= 255:\n",
    "                            R = 255\n",
    "                            G = escala - 255\n",
    "                            B = 0\n",
    "                        else:\n",
    "                            R = escala\n",
    "                            G = 0\n",
    "                            B = 0\n",
    "\n",
    "                    # Dibuja el contenedor y clase\n",
    "                    cv2.rectangle(imagen, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "                    cv2.putText(imagen, classNames[cls] , [x1, y1], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "            cv2.putText(imagen, f'Imagen {contador}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            # Muestra la imagen\n",
    "            cv2.imshow('Imagen', imagen)\n",
    "            \n",
    "            # Pasa de foto pulsando la tecla derecha\n",
    "            if cv2.waitKey(0) == 255 or cv2.waitKey(0) == 83:                \n",
    "                continue\n",
    "            \n",
    "    # Detenemos pulsado ESC\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "                \n",
    "\n",
    "# Cierra todas las ventanas al finalizar\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconocimiento de caracteres tras instalar pytesseract y tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tesseract\n",
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "# Previamente debes descargar los ejecutables\n",
    "# Si la ruta de Tesseract no está en el PATH, ruta al ejecutable\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Program Files/Tesseract-OCR/tesseract'\n",
    "\n",
    "# Lenguajes disponibles\n",
    "print(pytesseract.get_languages(config=''))\n",
    "\n",
    "#Cargo imagen y ocnvierto a RGB\n",
    "img = cv2.imread('toy.tif') \n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#Aplica reconocedor a imagen cargada\n",
    "print(pytesseract.image_to_string(img_rgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconocimiento decaracteres tras instalar easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "\n",
    "#Carga del modelo de lengua\n",
    "reader = easyocr.Reader(['es']) \n",
    "\n",
    "#Reconocimiento de una imagen\n",
    "result = reader.readtext('toy.tif')\n",
    "print(result)\n",
    "\n",
    "#Con restricción de caracteres reconocibles\n",
    "#result = reader.readtext('toy.tif', allowlist ='0123456789')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importa un dataset de Roboflow con 350 coches etiquetados con \"vehicle\" y \"license-plate\"\n",
    "\n",
    "Hay que poner tu API Key para poder descargarlo o entrar en el [dataset](https://public.roboflow.com/object-detection/license-plates-us-eu/3/download/yolov8) de Roboflow, descargarlo como zip y descomprimirlo en el proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "\n",
    "rf = Roboflow(api_key=\"YOUR-API-KEY\")\n",
    "project = rf.workspace(\"samrat-sahoo\").project(\"license-plates-us-eu\")\n",
    "dataset = project.version(3).download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import math \n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Carga del modelo\n",
    "model = YOLO('datasets/350_images/runs/detect/train4/weights/best.pt')\n",
    "\n",
    "classNames = [\"license-plate\", \"vehicle\"]\n",
    "\n",
    "#carpeta_fotos = \"C:\\\\Users\\\\miica\\\\Desktop\\\\Uni\\\\VC\\\\VC_Practica4\\\\otsedom.github.io\\\\VC\\\\P5\\\\Coches con matriculas\\\\Coches con matriculas\"\n",
    "carpeta_fotos = \"C:\\\\Users\\\\miica\\\\.conda\\\\envs\\\\VC_P1\\\\P5\\\\datasets\\\\350_images\\\\train\\\\images\"\n",
    "\n",
    "# Lista de fotos de la carpeta\n",
    "imagenes = os.listdir(carpeta_fotos)\n",
    "\n",
    "# Itera sobre cada archivo en la carpeta\n",
    "for img in imagenes:\n",
    "\n",
    "    # Verifica si el archivo es una imagen \n",
    "    if img.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "        # Construye la ruta completa de la imagen\n",
    "        ruta_imagen = os.path.join(carpeta_fotos, img)\n",
    "\n",
    "        # Lee la imagen\n",
    "        imagen = cv2.imread(ruta_imagen)\n",
    "        imagen_gris = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Perform inference on an image\n",
    "        results = model(imagen, stream=True)   \n",
    "        \n",
    "        # Para cada detección\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "            \n",
    "            for box in boxes:\n",
    "                # Contenedor\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "                \n",
    "                # Confianza\n",
    "                confidence = math.ceil((box.conf[0]*100))/100\n",
    "                print(\"Confidence --->\",confidence)\n",
    "\n",
    "                # Clase\n",
    "                cls = int(box.cls[0])\n",
    "                print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "                # Traducimos las etiquetas\n",
    "                if classNames[cls] == \"license-plate\":\n",
    "                    classNameTranslate = \"matricula\"\n",
    "                else:\n",
    "                    classNameTranslate = \"coche\"\n",
    "\n",
    "                if classNameTranslate == \"matricula\":\n",
    "                    # Cambiamos matricula a escala de grises\n",
    "                    mat = imagen_gris[y1:y2,x1:x2]\n",
    "                    \n",
    "                    #\n",
    "                    _, threshold_image = cv2.threshold(mat, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "                    \n",
    "                    # OCR\n",
    "                    text = pytesseract.image_to_string(threshold_image ,lang='eng', config='--psm 6 --oem 1')\n",
    "                    \n",
    "                    # Filtramos el texto devuelto al formato que debiera tener una matricula\n",
    "                    text_filtrado = re.search(r'[A-Z]{0,4}\\s*\\d{0,6}\\s*[A-Z]{0,4}\\s*', text)\n",
    "                    if text_filtrado:\n",
    "                        text_filtrado = text_filtrado.group()\n",
    "                        if text_filtrado == '':\n",
    "                            text_filtrado = text\n",
    "                    # Texto OCR\n",
    "                    cv2.putText(imagen, text_filtrado, (x1, y2+15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "                    # Dibuja el contenedor, la clase y el confidence\n",
    "                    cv2.rectangle(imagen, (x1, y1), (x2, y2), (255, 255, 0), 2)\n",
    "                    cv2.putText(imagen, str(classNameTranslate) + \" --> \" + str(confidence), [x1, y1 - 1], cv2.FONT_HERSHEY_SIMPLEX, 0.5, (150, 255, 0), 2)\n",
    "                \n",
    "                else:\n",
    "                    cv2.rectangle(imagen, (x1, y1), (x2, y2), (193, 182, 255), 2)\n",
    "                    cv2.putText(imagen, str(classNameTranslate) + \" --> \" + str(confidence), [x1, y1 - 1], cv2.FONT_HERSHEY_SIMPLEX, 0.5, (100, 255, 0), 2)\n",
    "\n",
    "        # Muestra la imagen\n",
    "        cv2.imshow('Imagen', imagen)\n",
    "\n",
    "        # Pasa de foto pulsando la tecla una tecla\n",
    "        if cv2.waitKey(0) == 255 or cv2.waitKey(0) == 83:                \n",
    "            continue\n",
    "            \n",
    "        # Detenemos pulsado ESC\n",
    "        if cv2.waitKey(50) == 27:\n",
    "            break\n",
    "# Destruye ventanas\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detección de Matrículas de Coches utilizando YOLOv8\n",
    "\n",
    "En esta práctica, nuestro objetivo es implementar un sistema de detección de matrículas de coches utilizando el modelo YOLOv8 para la detección de vehículos.\n",
    "\n",
    "### Primera parte ###\n",
    "#### Detección de matrículas usando bordes ####\n",
    "El proceso de detección consta de varios pasos para lograr obtener una matrícula:\n",
    "\n",
    "Primero, utilizamos el modelo YOLOv8 para detectar vehículos en la imagen. Si se identifica un coche o un camión (el modelo tiende a confundir coches grandes con camiones), dividimos la celda aproximadamente a la mitad para así acotar el lugar de búsqueda. Seguidamente, detectamos todos los bordes en la región de interés y filtramos por aquellos que tengan forma rectangular y superen cierto área. Este filtrado consta a su vez de varios pasos:\n",
    "\n",
    "1. **Filtrado de Rectángulos**: Para asegurarnos de que los bordes formen un rectángulo, calculamos el número de bordes obtenidos, buscando que sean cuatro. Así conseguimos quitar los bordes que tengan formas irregulares con menor o mayor número de bordes.\n",
    "\n",
    "2. **Filtrado por Área**: A su vez, usamos un pequeño umbral para el área y asegurarnos de quitar bordes que sean demasiado pequeños.\n",
    "\n",
    "5. **Filtrado por Diferencias de X e Y**: Calculamos las diferencias de X e Y de los lados de un rectángulo. Filtramos las matrículas donde estas diferencias son menores a cierto umbral, permitiendo que las fotos tomadas de lado también sean incluidas en las matrículas filtradas. Este es el paso que mayor filtrado realiza y el que más difícil y problemas ha dado para conseguir que el filtrado se ajuste a lo que buscamos. Hemos probado diversos métodos pero finalmente hemos optado por este ya que daba mejores resultados.\n",
    "\n",
    "### Segunda parte ###\n",
    "#### Detección de matrículas entrenando el modelo YOLOv8 y reconocimiento de texto ####\n",
    "\n",
    "En la segunda parte de esta práctica, entrenamos YOLOv8 con 50 épocas y un conjunto de datos de 350 imágenes. El conjunto de datos incluye imágenes de coches con matrículas y las etiquetas \"vehicle\" y \"license-plate\". Este conjunto de datos fue obtenido de [Roboflow](https://public.roboflow.com/object-detection/license-plates-us-eu/3/download/yolov8).\n",
    "\n",
    "Para la lectura de las matrículas, utilizamos la biblioteca pytesseract, que convierte una imagen en una cadena de texto. Cada vez que se detecta una matrícula, usamos pytesseract y realizamos un filtrado previo, ya que la cadena devuelta suele contener caracteres sin sentido provenientes de las distintas partes de la matrícula según su origen.\n",
    "\n",
    "Finalmente, dibujamos la matrícula en la propia ventana de la imagen para una fácil visualización.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('yolov7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54711ba1bddc392d48ca20e80feaa9b2e23d43069aa8b98ed16355091034ff6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
